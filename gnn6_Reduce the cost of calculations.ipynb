{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## محمد مهدی حاجی عباسی\n",
    "در این بخش قصد داریم یک مشکل رو بررسی کنیم و آن وقتی که سایز گراف هایی که داریم بزرگ باشه و در این حالت اجرا گرفتن از آن دشوار خواهد بود چرا که ابزار هایی که داریم محدود هستند.\n",
    "مثالی که اینجا استفاده شده گراف کوچیکی هست و فقط برای اموزش استفاده شده طبعا این روش روی راس ها و یال های میلیونی مورد استفاده قرار میگیرد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مبنای این روش مقاله :\n",
    "\n",
    "**Cluster-GCN** ([Chiang et al. (2019)](https://arxiv.org/abs/1905.07953)\n",
    "\n",
    "هست"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWn5yzT0LOzH",
    "outputId": "01140865-71bb-41af-a25f-995305be2258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBN2pGDueDpZ",
    "outputId": "5596858d-260d-4963-c375-c15ef25881c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PubMed():\n",
      "==================\n",
      "Number of graphs: 1\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "\n",
      "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
      "===============================================================================================================\n",
      "Number of nodes: 19717\n",
      "Number of edges: 88648\n",
      "Average node degree: 4.50\n",
      "Number of training nodes: 60\n",
      "Training node label rate: 0.003\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('==================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===============================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwhcs1L5fPjx",
    "outputId": "182d20fd-57ef-41bf-ed19-a0910d0f83de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1:\n",
      "=======\n",
      "Number of nodes in the current batch: 4928\n",
      "Data(x=[4928, 500], y=[4928], train_mask=[4928], val_mask=[4928], test_mask=[4928], edge_index=[2, 16174])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of nodes in the current batch: 4937\n",
      "Data(x=[4937, 500], y=[4937], train_mask=[4937], val_mask=[4937], test_mask=[4937], edge_index=[2, 17832])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of nodes in the current batch: 4927\n",
      "Data(x=[4927, 500], y=[4927], train_mask=[4927], val_mask=[4927], test_mask=[4927], edge_index=[2, 14712])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of nodes in the current batch: 4925\n",
      "Data(x=[4925, 500], y=[4925], train_mask=[4925], val_mask=[4925], test_mask=[4925], edge_index=[2, 18006])\n",
      "\n",
      "Iterated over 19717 of 19717 nodes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import ClusterData, ClusterLoader\n",
    "# با استفاده از این کتابخانه دیتا ها به 128 زیر گراف تبدیل میشوند\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "cluster_data = ClusterData(data, num_parts=128)  # 1. Create subgraphs.\n",
    "#ودر هر مرحله 32 تا از گراف ها آموزش می بیند\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=32, shuffle=True)  # 2. Stochastic partioning scheme.\n",
    "\n",
    "print()\n",
    "total_num_nodes = 0\n",
    "for step, sub_data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of nodes in the current batch: {sub_data.num_nodes}')\n",
    "    print(sub_data)\n",
    "    print()\n",
    "    total_num_nodes += sub_data.num_nodes\n",
    "\n",
    "print(f'Iterated over {total_num_nodes} of {data.num_nodes} nodes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در کنار این کار که انجام دادیم محاسبات رو کاهش داد کار دیگه ای که انجام میشه.\n",
    "استفاده ازdroputهست\n",
    "این کار از برزو رسانی یکسری از وزن ها جلو گیری می کند.\n",
    "\n",
    "که  این کار نیز هزینه محاسبات رو کاهش میدهد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1ho60LwfkHR",
    "outputId": "6d77312b-878c-49c6-d26c-588489d43b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(500, 16)\n",
      "  (conv2): GCNConv(16, 3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "#ساخت شبکه\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0JHjtY-CCkW"
   },
   "source": [
    "آموزش این شبکه عصبی گرافی به شکل قابل توجهی شبیه به آموزش شبکه‌های عصبی گرافی برای کلاس‌بندی گراف است. به جای عملکرد بر روی گراف به صورت کامل، ما در حال حاضر بر روی هر مینی‌بچ تکرار می‌کنیم و هر بچه را به طور مستقل بهینه‌سازی می‌کنیم:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "wLxawwYlgjDb",
    "outputId": "9240b29b-00d0-456b-d669-c9bf16480139"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.3333, Val Acc: 0.4160, Test Acc: 0.4070\n",
      "Epoch: 002, Train: 0.4833, Val Acc: 0.4420, Test Acc: 0.4270\n",
      "Epoch: 003, Train: 0.7333, Val Acc: 0.5220, Test Acc: 0.5160\n",
      "Epoch: 004, Train: 0.8333, Val Acc: 0.5920, Test Acc: 0.5930\n",
      "Epoch: 005, Train: 0.9167, Val Acc: 0.6920, Test Acc: 0.6810\n",
      "Epoch: 006, Train: 0.9000, Val Acc: 0.6680, Test Acc: 0.6680\n",
      "Epoch: 007, Train: 0.8833, Val Acc: 0.6520, Test Acc: 0.6530\n",
      "Epoch: 008, Train: 0.9167, Val Acc: 0.7020, Test Acc: 0.6940\n",
      "Epoch: 009, Train: 0.9333, Val Acc: 0.7340, Test Acc: 0.7290\n",
      "Epoch: 010, Train: 0.9333, Val Acc: 0.6880, Test Acc: 0.6900\n",
      "Epoch: 011, Train: 0.9500, Val Acc: 0.7240, Test Acc: 0.7330\n",
      "Epoch: 012, Train: 0.9500, Val Acc: 0.7500, Test Acc: 0.7300\n",
      "Epoch: 013, Train: 0.9667, Val Acc: 0.7680, Test Acc: 0.7530\n",
      "Epoch: 014, Train: 0.9667, Val Acc: 0.7600, Test Acc: 0.7450\n",
      "Epoch: 015, Train: 0.9667, Val Acc: 0.7680, Test Acc: 0.7550\n",
      "Epoch: 016, Train: 0.9667, Val Acc: 0.7660, Test Acc: 0.7630\n",
      "Epoch: 017, Train: 0.9667, Val Acc: 0.7660, Test Acc: 0.7600\n",
      "Epoch: 018, Train: 0.9667, Val Acc: 0.7740, Test Acc: 0.7650\n",
      "Epoch: 019, Train: 0.9667, Val Acc: 0.7800, Test Acc: 0.7610\n",
      "Epoch: 020, Train: 0.9667, Val Acc: 0.7820, Test Acc: 0.7680\n",
      "Epoch: 021, Train: 0.9667, Val Acc: 0.7860, Test Acc: 0.7790\n",
      "Epoch: 022, Train: 0.9667, Val Acc: 0.7880, Test Acc: 0.7820\n",
      "Epoch: 023, Train: 0.9667, Val Acc: 0.7920, Test Acc: 0.7880\n",
      "Epoch: 024, Train: 0.9667, Val Acc: 0.7940, Test Acc: 0.7880\n",
      "Epoch: 025, Train: 0.9833, Val Acc: 0.7920, Test Acc: 0.7780\n",
      "Epoch: 026, Train: 0.9833, Val Acc: 0.8000, Test Acc: 0.7750\n",
      "Epoch: 027, Train: 0.9667, Val Acc: 0.8080, Test Acc: 0.7800\n",
      "Epoch: 028, Train: 0.9667, Val Acc: 0.8040, Test Acc: 0.7920\n",
      "Epoch: 029, Train: 0.9667, Val Acc: 0.7980, Test Acc: 0.7880\n",
      "Epoch: 030, Train: 0.9833, Val Acc: 0.7980, Test Acc: 0.7880\n",
      "Epoch: 031, Train: 0.9833, Val Acc: 0.8040, Test Acc: 0.7800\n",
      "Epoch: 032, Train: 0.9833, Val Acc: 0.8020, Test Acc: 0.7770\n",
      "Epoch: 033, Train: 0.9667, Val Acc: 0.8120, Test Acc: 0.7900\n",
      "Epoch: 034, Train: 0.9833, Val Acc: 0.7980, Test Acc: 0.7900\n",
      "Epoch: 035, Train: 0.9833, Val Acc: 0.7960, Test Acc: 0.7930\n",
      "Epoch: 036, Train: 0.9833, Val Acc: 0.7980, Test Acc: 0.7900\n",
      "Epoch: 037, Train: 0.9833, Val Acc: 0.7960, Test Acc: 0.7930\n",
      "Epoch: 038, Train: 0.9833, Val Acc: 0.7980, Test Acc: 0.7920\n",
      "Epoch: 039, Train: 0.9833, Val Acc: 0.8040, Test Acc: 0.7910\n",
      "Epoch: 040, Train: 0.9833, Val Acc: 0.7980, Test Acc: 0.7930\n",
      "Epoch: 041, Train: 0.9833, Val Acc: 0.7960, Test Acc: 0.7940\n",
      "Epoch: 042, Train: 0.9833, Val Acc: 0.7960, Test Acc: 0.7900\n",
      "Epoch: 043, Train: 0.9833, Val Acc: 0.7940, Test Acc: 0.7920\n",
      "Epoch: 044, Train: 0.9833, Val Acc: 0.8000, Test Acc: 0.7950\n",
      "Epoch: 045, Train: 0.9833, Val Acc: 0.7960, Test Acc: 0.7950\n",
      "Epoch: 046, Train: 0.9833, Val Acc: 0.8000, Test Acc: 0.8000\n",
      "Epoch: 047, Train: 0.9833, Val Acc: 0.8020, Test Acc: 0.7820\n",
      "Epoch: 048, Train: 0.9833, Val Acc: 0.8000, Test Acc: 0.7730\n",
      "Epoch: 049, Train: 0.9833, Val Acc: 0.8060, Test Acc: 0.8020\n",
      "Epoch: 050, Train: 0.9833, Val Acc: 0.8020, Test Acc: 0.7940\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "\n",
    "      for sub_data in train_loader:  # Iterate over each mini-batch.\n",
    "          out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
    "          loss = criterion(out[sub_data.train_mask], sub_data.y[sub_data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "          loss.backward()  # Derive gradients.\n",
    "          optimizer.step()  # Update parameters based on gradients.\n",
    "          optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      \n",
    "      accs = []\n",
    "      for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "          correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
    "          accs.append(int(correct.sum()) / int(mask.sum()))  # Derive ratio of correct predictions.\n",
    "      return accs\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "و در نهایت لینک چند منبع مناسب برای مطالعه بیشتر کد های مربوط به این زمینه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[PyG's documentation](https://pytorch-geometric.readthedocs.io/en/latest/?badge=latest)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[مثال های بیشتر](https://github.com/rusty1s/pytorch_geometric/tree/master/examples)**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
